{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "355UKMUQJxFd"
   },
   "source": [
    "# Scalable Diffusion Models with Transformer (DiT)\n",
    "\n",
    "This notebook samples from pre-trained DiT models. DiTs are class-conditional latent diffusion models trained on ImageNet that use transformers in place of U-Nets as the DDPM backbone. DiT outperforms all prior diffusion models on the ImageNet benchmarks.\n",
    "\n",
    "[Project Page](https://www.wpeebles.com/DiT) | [HuggingFace Space](https://huggingface.co/spaces/wpeebles/DiT) | [Paper](http://arxiv.org/abs/2212.09748) | [GitHub](github.com/facebookresearch/DiT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.30.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting importlib-metadata (from diffusers)\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.13.1)\n",
      "Collecting huggingface-hub>=0.23.2 (from diffusers)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.3)\n",
      "Collecting regex!=2019.12.17 (from diffusers)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.31.0)\n",
      "Collecting safetensors>=0.3.1 (from diffusers)\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (10.0.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.2.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.17.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.9.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata->diffusers)\n",
      "  Downloading zipp-3.20.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2023.11.17)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Downloading diffusers-0.30.2-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading zipp-3.20.1-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: zipp, safetensors, regex, importlib-metadata, huggingface-hub, diffusers, timm\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/mchen/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script diffusers-cli is installed in '/home/mchen/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed diffusers-0.30.2 huggingface-hub-0.24.6 importlib-metadata-8.4.0 regex-2024.7.24 safetensors-0.4.4 timm-1.0.9 zipp-3.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers timm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from torchvision.utils import save_image\n",
    "from diffusion import create_diffusion\n",
    "from models import DiT_XL_8\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cpu\":\n",
    "    print(\"GPU not found. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (x_embedder): PatchEmbed(\n",
       "    (proj): Conv2d(5, 1152, kernel_size=(8, 8), stride=(8, 8))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1152, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(1001, 1152)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-27): 28 x DiTBlock(\n",
       "      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "        (act): GELU(approximate='tanh')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1152, out_features=6912, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((1152,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=1152, out_features=640, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=1152, out_features=2304, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 256 #@param [256, 512]\n",
    "# Load model:\n",
    "model = DiT_XL_8(input_size=image_size)\n",
    "state_dict = torch.load('results/004-DiT-XL-8/checkpoints/latest.pt', map_location='cpu')\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model = model.to(device)\n",
    "model.eval() # important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebad7d3e8af41cfb6019e8af09d9b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set user inputs:\n",
    "seed = 0 #@param {type:\"number\"}\n",
    "torch.manual_seed(seed)\n",
    "num_sampling_steps = 1000 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
    "# cfg_scale = 4 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
    "cfg_scale = 1\n",
    "class_labels = 207, 360, 387, 974, 88, 979, 417, 279 #@param {type:\"raw\"}\n",
    "samples_per_row = 4 #@param {type:\"number\"}\n",
    "\n",
    "# Create diffusion object:\n",
    "diffusion = create_diffusion(str(num_sampling_steps))\n",
    "\n",
    "# Create sampling noise:\n",
    "n = len(class_labels)\n",
    "z = torch.randn(n, 5, image_size, image_size, device=device)\n",
    "y = torch.tensor(class_labels, device=device)\n",
    "\n",
    "# Setup classifier-free guidance:\n",
    "z = torch.cat([z, z], 0)\n",
    "y_null = torch.tensor([1000] * n, device=device)\n",
    "y = torch.cat([y, y_null], 0)\n",
    "model_kwargs = dict(y=y, cfg_scale=cfg_scale)\n",
    "\n",
    "# Sample images:\n",
    "samples = diffusion.p_sample_loop(\n",
    "    model.forward_with_cfg, z.shape, z, clip_denoised=False, \n",
    "    model_kwargs=model_kwargs, progress=True, device=device\n",
    ")\n",
    "samples, _ = samples.chunk(2, dim=0)  # Remove null class samples\n",
    "\n",
    "# Save and display images:\n",
    "# save_image(samples, \"sample.png\", nrow=int(samples_per_row), \n",
    "#            normalize=True, value_range=(-1, 1))\n",
    "# samples = Image.open(\"sample.png\")\n",
    "# display(samples)\n",
    "\n",
    "points = samples.view(samples.shape[0], samples.shape[1], -1).add(1).mul(.5) # in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = points[:, :3].clamp(0,1).cpu()\n",
    "pos = points[:, 3:].clamp(0,1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6820631cf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 4\n",
    "plt.scatter(pos[idx,0], pos[idx,1], c=rgb[idx].T, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "coords = samples[0, -2:].view(2,-1).cpu()\n",
    "\n",
    "plt.scatter(coords[0], coords[1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
